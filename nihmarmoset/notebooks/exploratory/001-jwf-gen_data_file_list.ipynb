{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate List of Data Files and Write to CSV\n",
    "\n",
    "#### There are 4 basic data types\n",
    "\n",
    "* `mp4`\n",
    "  - RGB frames\n",
    "* `avi`\n",
    "  - depth images\n",
    "* `ogg`\n",
    "  - audio file\n",
    "* `log`\n",
    "  - information about data files. Format seems to vary, so check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Some Standard Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/fisher/projects/NIH/git/nihmarmoset/notebooks/exploratory'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "import glob\n",
    "from typing import List, Tuple, Union\n",
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from IPython.display import display, HTML\n",
    "from itertools import *\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy.special as sc\n",
    "import dotenv\n",
    "import progressbar\n",
    "dotenv.load_dotenv(dotenv.find_dotenv())\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import some local packages\n",
    "\n",
    "This may not work unless \n",
    "\n",
    "1. setup.py is in the repo, *AND* \n",
    "2. `pip install -e .` was run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from src.data.dataset import load_method_by_otu_type\n",
    "#from src.data.dataset import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print some of the environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  PROJECT_ROOT: /Users/fisher/projects/NIH/git/nihmarmoset\n",
      "  PROJECT_DATA: /Volumes/JWFExtDat/data/marmoset/data\n",
      "PROJECT_MODELS: /Volumes/JWFExtDat/data/marmoset/models\n",
      "    PYTHONPATH: /usr/local/lib:./:/Users/fisher/projects/NIH/git/nihmarmoset/src\n",
      "PYTHONBUFFERED: 1\n"
     ]
    }
   ],
   "source": [
    "print(f'  PROJECT_ROOT: {os.getenv(\"PROJECT_ROOT\")}')\n",
    "print(f'  PROJECT_DATA: {os.getenv(\"PROJECT_DATA\")}')\n",
    "print(f'PROJECT_MODELS: {os.getenv(\"PROJECT_MODELS\")}')\n",
    "print(f'    PYTHONPATH: {os.getenv(\"PYTHONPATH\")}')\n",
    "print(f'PYTHONBUFFERED: {os.getenv(\"PYTHONUBUFFERED\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define some local functions\n",
    "* `DataFileListbyType` - generate list of data files available in various subdirectories where `typstr` is one of `otu`, `effl`, or `wthr`.\n",
    "* `datfildf` - create data frame that contains details of each data file.\n",
    "* `cond_literal` - conditional use of `literal_eval` for fields with things like `tuples` or `arrays`\n",
    "* `getfilfromdf` - extracts full file name from datfildf.\n",
    "* `gethdrrowsfromdf` - extracts `headerrows` argument from datfildf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataFileListbyType(tgtextlst,subdir):\n",
    "    datdir = f'{os.getenv(\"PROJECT_DATA\")}/{subdir}'\n",
    "    #\n",
    "    # Get list of subdirectories in subdir\n",
    "    #\n",
    "    subdirlst = next(os.walk(f'{datdir}'))[1]\n",
    "    #\n",
    "    # Initialize lists\n",
    "    #\n",
    "    fillst = []\n",
    "    dirlst = []\n",
    "    extlst = []\n",
    "    #\n",
    "    # iterate through subdirectories and find files that have extensions\n",
    "    #\n",
    "    for tmpdir in subdirlst:\n",
    "        fullpath = f'{datdir}/{tmpdir}/'\n",
    "        # used `glob` to allow for wildcards and avoid extraneous dotfiles\n",
    "        dirlst = dirlst+[os.path.dirname(sub).replace(datdir,subdir) \n",
    "                         for sub in glob.glob(f'{datdir}/{tmpdir}/[0-9,a-z,A-Z]*.*') \n",
    "                         if os.path.splitext(sub)[1].replace('.','') in tgtextlst]\n",
    "        fillst = fillst+[os.path.basename(sub) \n",
    "                         for sub in glob.glob(f'{datdir}/{tmpdir}/[0-9,a-z,A-Z]*.*') \n",
    "                         if os.path.splitext(sub)[1].replace('.','') in tgtextlst]\n",
    "        extlst = extlst+[os.path.splitext(sub)[1].replace('.','') \n",
    "                         for sub in glob.glob(f'{datdir}/{tmpdir}/[0-9,a-z,A-Z]*.*') \n",
    "                         if os.path.splitext(sub)[1].replace('.','') in tgtextlst]\n",
    "    datfildf = pd.DataFrame(data={\"subdir\":dirlst,\"filename\":fillst,\"extension\":extlst})\n",
    "    return datfildf\n",
    "def datfildf(fillst,typstr,rawsubdir):\n",
    "    df = pd.DataFrame(fillst,columns=['raw_name'])\n",
    "    df.insert(0,'raw_subdir',f'{rawsubdir}/{typstr}')\n",
    "    df['raw_type'] = ''\n",
    "    df['skiprowslist'] = ''\n",
    "    df['header'] = ''\n",
    "    df['ldmethod'] = ''\n",
    "    for index, row in df.iterrows():\n",
    "        extloc = row['raw_name'].find('.')\n",
    "        extstr = row['raw_name'][extloc+1:]\n",
    "        row['raw_type'] = typstr\n",
    "        if row['raw_type'] == 'otu':\n",
    "            row['skiprowslist'] = [1,2,3,4]\n",
    "            row['header'] = [0,1,2,3,4]\n",
    "        row['ldmethod'] = load_method_by_otu_type(extstr)\n",
    "    return df\n",
    "def cond_literal(str):\n",
    "    return str if str == '' else literal_eval(str)\n",
    "def getfilfromdf(indx,fildf):\n",
    "    rawdir = f\"{os.getenv('PROJECT_DATA')}/{fildf['raw_subdir'].iloc[indx]}\"\n",
    "    rawfilin = fildf['raw_name'].iloc[indx]\n",
    "    return f'{rawdir}/{rawfilin}'\n",
    "def gethdrrowsfromdf(indx,fildf):\n",
    "    return fildf['header'].iloc[indx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get list of various data sets \n",
    "\n",
    "* `extsubdir` is the *relative* path to the data\n",
    "   * Assumes a base directory of `{PROJECT_DATA}/`  \n",
    "* `extlst` list of extensions used to filter list\n",
    "   * Using `['mp4','avi','ogg','log']` below because those are the primary data files of interest.\n",
    "   * The function defined here specifically looks for subdirectories **one** level down from `extsubdir`. Could probably modify this procedure when there is interest in searching the directory to tree to an arbitrary depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "extsubdir = 'external/rgbda_record_data'\n",
    "extlst = ['mp4','avi','ogg','log']\n",
    "datfildf = DataFileListbyType(extlst,extsubdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display data frame containing list of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subdir</th>\n",
       "      <th>filename</th>\n",
       "      <th>extension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>external/rgbda_record_data/20170524</td>\n",
       "      <td>recording-2017-05-24_15_14_33.mp4</td>\n",
       "      <td>mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>external/rgbda_record_data/20170524</td>\n",
       "      <td>recording-2017-05-24_15_14_33.log</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>external/rgbda_record_data/20170524</td>\n",
       "      <td>recording-2017-05-24_15_27_58.log</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>external/rgbda_record_data/20170524</td>\n",
       "      <td>recording-2017-05-24_15_27_58.mp4</td>\n",
       "      <td>mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>external/rgbda_record_data/20170524</td>\n",
       "      <td>recording-2017-05-24_15_14_33.avi</td>\n",
       "      <td>avi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>external/rgbda_record_data/20170524</td>\n",
       "      <td>recording-2017-05-24_15_14_33.ogg</td>\n",
       "      <td>ogg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>external/rgbda_record_data/20170524</td>\n",
       "      <td>recording-2017-05-24_15_27_58.ogg</td>\n",
       "      <td>ogg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>external/rgbda_record_data/20170524</td>\n",
       "      <td>recording-2017-05-24_15_27_58.avi</td>\n",
       "      <td>avi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>external/rgbda_record_data/20170224</td>\n",
       "      <td>recording-2017-02-24_14_23_25.ogg</td>\n",
       "      <td>ogg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>external/rgbda_record_data/20170224</td>\n",
       "      <td>recording-2017-02-24_14_26_16.ogg</td>\n",
       "      <td>ogg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>external/rgbda_record_data/20170224</td>\n",
       "      <td>recording-2017-02-24_14_26_16.avi</td>\n",
       "      <td>avi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>external/rgbda_record_data/20170224</td>\n",
       "      <td>recording-2017-02-24_14_23_25.avi</td>\n",
       "      <td>avi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>external/rgbda_record_data/20170224</td>\n",
       "      <td>recording-2017-02-24_14_26_16.mp4</td>\n",
       "      <td>mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>external/rgbda_record_data/20170224</td>\n",
       "      <td>recording-2017-02-24_14_23_25.log</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>external/rgbda_record_data/20170224</td>\n",
       "      <td>recording-2017-02-24_14_23_25.mp4</td>\n",
       "      <td>mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>external/rgbda_record_data/20170224</td>\n",
       "      <td>recording-2017-02-24_14_26_16.log</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(datfildf.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group groupings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>subdir</th>\n",
       "      <th>filename</th>\n",
       "      <th>extension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>external/rgbda_record_data/20170224</td>\n",
       "      <td>recording-2017-02-24_14_23_25.ogg</td>\n",
       "      <td>ogg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>external/rgbda_record_data/20170224</td>\n",
       "      <td>recording-2017-02-24_14_26_16.ogg</td>\n",
       "      <td>ogg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>external/rgbda_record_data/20170224</td>\n",
       "      <td>recording-2017-02-24_14_26_16.avi</td>\n",
       "      <td>avi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>external/rgbda_record_data/20170224</td>\n",
       "      <td>recording-2017-02-24_14_23_25.avi</td>\n",
       "      <td>avi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>external/rgbda_record_data/20170224</td>\n",
       "      <td>recording-2017-02-24_14_26_16.mp4</td>\n",
       "      <td>mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>external/rgbda_record_data/20170224</td>\n",
       "      <td>recording-2017-02-24_14_23_25.log</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>external/rgbda_record_data/20170224</td>\n",
       "      <td>recording-2017-02-24_14_23_25.mp4</td>\n",
       "      <td>mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>external/rgbda_record_data/20170224</td>\n",
       "      <td>recording-2017-02-24_14_26_16.log</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>external/rgbda_record_data/20170524</td>\n",
       "      <td>recording-2017-05-24_15_14_33.mp4</td>\n",
       "      <td>mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>external/rgbda_record_data/20170524</td>\n",
       "      <td>recording-2017-05-24_15_14_33.log</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>external/rgbda_record_data/20170524</td>\n",
       "      <td>recording-2017-05-24_15_27_58.log</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>external/rgbda_record_data/20170524</td>\n",
       "      <td>recording-2017-05-24_15_27_58.mp4</td>\n",
       "      <td>mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>external/rgbda_record_data/20170524</td>\n",
       "      <td>recording-2017-05-24_15_14_33.avi</td>\n",
       "      <td>avi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>external/rgbda_record_data/20170524</td>\n",
       "      <td>recording-2017-05-24_15_14_33.ogg</td>\n",
       "      <td>ogg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>external/rgbda_record_data/20170524</td>\n",
       "      <td>recording-2017-05-24_15_27_58.ogg</td>\n",
       "      <td>ogg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>external/rgbda_record_data/20170524</td>\n",
       "      <td>recording-2017-05-24_15_27_58.avi</td>\n",
       "      <td>avi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(datfildf.sort_values(by=['subdir']).to_html(index=False,notebook=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([('external/rgbda_record_data/20170524', ...),\n",
       "            ('external/rgbda_record_data/20170524', ...),\n",
       "            ('external/rgbda_record_data/20170524', ...),\n",
       "            ('external/rgbda_record_data/20170524', ...),\n",
       "            ('external/rgbda_record_data/20170524', ...),\n",
       "            ('external/rgbda_record_data/20170524', ...),\n",
       "            ('external/rgbda_record_data/20170524', ...),\n",
       "            ('external/rgbda_record_data/20170524', ...),\n",
       "            ('external/rgbda_record_data/20170224', ...),\n",
       "            ('external/rgbda_record_data/20170224', ...),\n",
       "            ('external/rgbda_record_data/20170224', ...),\n",
       "            ('external/rgbda_record_data/20170224', ...),\n",
       "            ('external/rgbda_record_data/20170224', ...),\n",
       "            ('external/rgbda_record_data/20170224', ...),\n",
       "            ('external/rgbda_record_data/20170224', ...),\n",
       "            ('external/rgbda_record_data/20170224', ...)],\n",
       "           names=['subdir', 'filename', 'extension'])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display((pd.MultiIndex.from_frame(datfildf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store file list in dataframe\n",
    "\n",
    "The idea of creating this data frame was motivated by contending with multiple file formats (even for the same data type). This data frame would contain the list of files along with the functions parameters needed to read them and reformat when moving from `external` to `raw`. The intent was for the file to be in `.csv` format and to be human-editable (assuming an automated approach wouldn't be available). There is the danger of over-writing manual edits, so the designed process was not robust.\n",
    "\n",
    "However, the formats have been standardized somewhat, so this may be super-fluous.\n",
    "\n",
    "* the external data source are password protected `.xlsx` spread sheets, these have been *manually* saved as `.csv` under the `raw` subdirectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "otufildf = datfildf(otudatfillst,otustr,rawsubdir)\n",
    "efflfildf = datfildf(effldatfillst,efflstr,rawsubdir)\n",
    "wthrfildf = datfildf(wthrdatfillst,wthrstr,rawsubdir)\n",
    "display(HTML(otufildf.to_html()))\n",
    "display(HTML(wthrfildf.to_html()))\n",
    "display(HTML(efflfildf.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge [etu, effl, wthr]fildf into a single data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datfildf = pd.concat([otufildf,efflfildf,wthrfildf])\n",
    "display(datfildf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write File List to CSV File\n",
    "* Idea is to include parameters that are relevant to loading a particular file, although, this was only an issue when the \"external\" data was in varying formats.\n",
    "* For now, a convenient listing of the available data files.\n",
    "* If the idea is to run this *once* (in a notebook or a script), still need to work out process that ensures it does not overwrite any manual edits.\n",
    "* Writing this to the `raw` directory might be questionable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datcsvfil = f'{os.getenv(\"PROJECT_DATA\")}/{rawsubdir}/datfildf.csv'\n",
    "print(f'CSV output file: {datcsvfil}')\n",
    "datfildf.to_csv(datcsvfil,na_rep='',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I am leaving the next two cells in place because they provide examples of \n",
    "* using `cond_literal`/`literal_eval` when reading `.csv`\n",
    "  * this option is needed when reading the file back in so that fields with arrays and tuples are read as such. The converter is defined above.\n",
    "  * notebooks that load these files should start with this csv file.\n",
    "\n",
    "#### Re-read file back in as sanity check\n",
    "* Originally, this was a *different* file\n",
    "    * the intent being that it would be edited by hand (if necessary) to provide parameters for reading\n",
    "    * the script could only be run once, though, since there isn't error checking (currently). Otherwise, hand edits would be over-written (oh, my!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datfil2df = pd.read_csv(datcsvfil,converters={'skiprowslist': cond_literal,'header': cond_literal})\n",
    "display(HTML(datfil2df.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXAMPLE - Load index 5\n",
    "* This happens to be the smallest otu file.\n",
    "* **Everything** after the next cell are to illustrate operations after loading the data.\n",
    "* The cells above and below are where most analysis notebooks (or scripts) would start **presuming** the csv data file has been created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "otuindx = 5\n",
    "otufil = getfilfromdf(otuindx,datfildf)\n",
    "otuhdrrows = gethdrrowsfromdf(otuindx,datfildf)\n",
    "otuhdrdf = ld_otu_header_df(otufil,headerrows=otuhdrrows)\n",
    "otudf= ld_otu_df(otufil,headerrows=otuhdrrows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading OTU Files results in a df with a multi-index over columns\n",
    " * `ld_otu_header_df` grabs the header rows and creates a df over the multi-indices.\n",
    "\n",
    "   This is useful for creating various plotting indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML(otuhdrdf.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the unique values found in *some* of the indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(otuhdrdf['Collection Site'].unique())\n",
    "display(otuhdrdf['Collection Season'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the data frame itself (with multi-indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(otudf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter multi-index by key\n",
    "\n",
    "Some examples of filtering the multi-indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "otudf.xs('TH01',level=3,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Abundance Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "otudatTH01 = otudf.xs('TH01',level=3,axis=1).to_numpy()\n",
    "otudatTH06 = otudf.xs('TH06',level=3,axis=1).to_numpy()\n",
    "otudatTH07 = otudf.xs('TH07',level=3,axis=1).to_numpy()\n",
    "display(otudatTH01.shape)\n",
    "display(np.sum(otudatTH01,axis=0).shape)\n",
    "display(otudf.xs(('TH06','Winter'),axis=1,level=[3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dftmp = otudf.xs(('TH06','Winter'),axis=1,level=[3,4])\n",
    "dftmp = otudf.xs('TH06',axis=1,level=3)\n",
    "display(dftmp.iloc[0:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(dftmp.iloc[0:250],row_cluster=False,metric=\"correlation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftmp['12/3/18'].plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrmotudatTH01=otudatTH01/np.sum(otudatTH01,axis=0)\n",
    "nrmotudatTH06=otudatTH06/np.sum(otudatTH06,axis=0)\n",
    "nrmotudatTH07=otudatTH07/np.sum(otudatTH07,axis=0)\n",
    "plt.figure(figsize=default_figsize)\n",
    "plt.plot(np.sum(otudatTH01,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cumulative_local_weights(np.transpose(nrmotudatTH01),figsize=(16,8),ground_truth=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cumulative_local_weights(np.transpose(nrmotudatTH06),figsize=(16,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cumulative_local_weights(np.transpose(nrmotudatTH07),figsize=(16,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDP Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
